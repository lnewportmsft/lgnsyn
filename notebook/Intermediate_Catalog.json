{
	"name": "Intermediate_Catalog",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "lgnsynspark32",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "3dba69b9-6d8a-4459-ad2d-3ba36dde2cc0"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/65c04546-fce4-4b3c-be44-dac0e5324e24/resourceGroups/lgnsynapse/providers/Microsoft.Synapse/workspaces/lgnsynapse/bigDataPools/lgnsynspark32",
				"name": "lgnsynspark32",
				"type": "Spark",
				"endpoint": "https://lgnsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/lgnsynspark32",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.2",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"import uuid\n",
					"import pyspark.sql.functions as F\n",
					"from pyspark.sql.functions import col\n",
					"from pyspark.sql.types import StringType,DateType,LongType,IntegerType,TimestampType"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Collect the raw catalog data from all three source systems"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From Fourth Coffee"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fc_movies = spark.read.csv(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/fourthcoffee/Movies.csv\", header='true', inferSchema='true')\n",
					"fc_actors = spark.read.csv(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/fourthcoffee/Actors.csv\", header='true', inferSchema='true')\n",
					"fc_movie_actors = spark.read.csv(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/fourthcoffee/MovieActors.csv\", header='true', inferSchema='true')\n",
					"fc_mappings = spark.read.csv(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/fourthcoffee/OnlineMovieMappings.csv\", header='true', inferSchema='true')\n",
					"\n",
					"# Use the MovieActors data to join the actor information. Left join to preserve movies where the actors are not found\n",
					"# Use the OnlineMovieMappings data to bring in the ids of movies which are also found in the Southridge Video catalog,\n",
					"# again using the left join to preserve movies which are not matched.\n",
					"\n",
					"fc_catalog = fc_movies \\\n",
					"  .join(fc_movie_actors, on='MovieId', how='left') \\\n",
					"  .join(fc_actors, on='ActorId', how='left') \\\n",
					"  .join(fc_mappings, on='MovieId', how='left')"
				],
				"execution_count": 4
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From VanArsdel"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"va_movies = spark.read.parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/vanarsdel/dboMovies.parquet\")\n",
					"va_actors = spark.read.parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/vanarsdel/dboActors.parquet\")\n",
					"va_movie_actors = spark.read.parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/vanarsdel/dboMovieActors.parquet\")\n",
					"va_mappings = spark.read.parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/vanarsdel/dboOnlineMovieMappings.parquet\")\n",
					"\n",
					"# Use the MovieActors data to join the actor information. Left join to preserve movies where the actors are not found\n",
					"# Use the OnlineMovieMappings data to bring in the ids of movies which are also found in the Southridge Video catalog,\n",
					"# again using the left join to preserve movies which are not matched.\n",
					"\n",
					"va_catalog = va_movies \\\n",
					"  .join(va_movie_actors, on='MovieId', how='left') \\\n",
					"  .join(va_actors, on='ActorId', how='left') \\\n",
					"  .join(va_mappings, on='MovieId', how='left')"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"source": [
					"## From Southridge"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# After reading the JSON, explode the actors array to create multiple rows per movie, each having a single actor name\n",
					"# Drop the original actors array, as it is then no longer needed\n",
					"# Also drop the Cosmos DB metadata, as it will not be valuable here\n",
					"\n",
					"import pyspark.sql.functions as F\n",
					"\n",
					"sr_catalog = spark.read.json(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/raw/southridge/catalog/movies.json\") \\\n",
					"  .withColumn('actor', F.explode('actors')) \\\n",
					"  .drop('actors', '_attachments', '_etag', '_rid', '_self', '_ts')\n",
					"\n",
					"display(sr_catalog)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"source": [
					"# Observe inconsistencies in the data types and formats\n",
					"\n",
					"Let's take a look at the following discrepencies which could cause fatal errors in downstream processing."
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Release dates and availability dates\n",
					"\n",
					"FourthCoffee and VanArsdel, Ltd. both seem to track the ReleaseDate for each movie. These are stored as strings, and we'll need to look into the formats they've used.\n",
					"\n",
					"Southridge Video is storing a releaseYear, an availabilityDate, and a streamingAvailabilityDate."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fc_dates = fc_catalog.select(col('ReleaseDate').alias('FcReleaseDate'), col('MovieId'), col('OnlineMovieId'))\n",
					"va_dates = va_catalog.select(col('ReleaseDate').alias('VaReleaseDate'), col('MovieId'), col('OnlineMovieId'))\n",
					"sr_dates = sr_catalog.select(*['id', 'releaseYear', 'availabilityDate', 'streamingAvailabilityDate'])\n",
					"\n",
					"joined_dates = sr_dates \\\n",
					"  .join(fc_dates, F.upper(sr_dates.id) == fc_dates.OnlineMovieId, how='left') \\\n",
					"  .join(va_dates, sr_dates.id == va_dates.OnlineMovieId, how='left')\n",
					"\n",
					"joined_dates \\\n",
					"  .filter('FcReleaseDate is not null AND VaReleaseDate is not null') \\\n",
					"  .limit(1) \\\n",
					"  .collect()"
				],
				"execution_count": 7
			},
			{
				"cell_type": "markdown",
				"source": [
					"### Looking at the dates\n",
					"\n",
					"```text\n",
					"[Row(id='300e034e-4260-49ed-85e2-39a8d5030713',\n",
					"    releaseYear=2015,\n",
					"    availabilityDate='2017-07-25 00:00:00',\n",
					"    streamingAvailabilityDate='2017-09-19 00:00:00',\n",
					"    FcReleaseDate='07-25-2017',\n",
					"    OnlineMovieId='300E034E-4260-49ED-85E2-39A8D5030713',\n",
					"    VaReleaseDate='07-25-2017',\n",
					"    OnlineMovieId='300e034e-4260-49ed-85e2-39a8d5030713')]\n",
					"```\n",
					"\n",
					"Above, we see that:  \n",
					"  - Southridge has recorded a 2015 releaseYear for this movie\n",
					"  - Southridge has recorded that the movie is available as of 25 Jul 2017\n",
					"  - Southridge has recorded that the movie is available for streaming as of 19 Sep 2017\n",
					"  - Fourth Coffee has recorded that the movie has a ReleaseDate of 25 Jul 2017\n",
					"  - VanArsdel, Ltd. has similarly recorded the ReleaseDate as 25 Jul 2017\n",
					"\n",
					"It looks like Fourth Coffee is tracking the \"release\" in terms of when it became available to rent. Only Southridge Video has tracked the original theatrical release year. This detail was useful for their web-based front-end, but the brick and mortar stores previously had no business need for it.\n",
					"\n",
					"Each of the source system has stored dates in different formats, but we will use true date types in our conformed intermediate schema."
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"> Note: We are not only parsing the dates here, but also adding a column to track the SourceSystemId"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"fc_catalog = fc_catalog \\\n",
					"  .withColumn('ReleaseDate', F.to_date(col('ReleaseDate'), 'MM-dd-yyyy')) \\\n",
					"  .withColumn('SourceSystemId', F.lit('FC'))\n",
					"\n",
					"va_catalog = va_catalog \\\n",
					"  .withColumn('ReleaseDate', F.to_date(col('ReleaseDate'), 'MM-dd-yyyy')) \\\n",
					"  .withColumn('SourceSystemId', F.lit('VA'))\n",
					"\n",
					"sr_catalog = sr_catalog \\\n",
					"  .withColumn('availabilityDate', F.to_date(col('availabilityDate'), 'yyyy-MM-dd HH:mm:ss')) \\\n",
					"  .withColumn('streamingAvailabilityDate', F.to_date(col('streamingAvailabilityDate'), 'yyyy-MM-dd HH:mm:ss')) \\\n",
					"  .withColumn('SourceSystemId', F.lit('SR'))"
				],
				"execution_count": 8
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Unioning the data\n",
					"\n",
					"### Target schema\n",
					"\n",
					"Looking ahead, we will keep every source record from every catalog, so we don't need to join here.\n",
					"However, we will need to map columns to a consistent schema.\n",
					"\n",
					"```\n",
					"SourceSystemId:              Use the SourceSystemId we added in the previous cell.\n",
					"CatalogId:                   Use a new unique identifier.\n",
					"SourceSystemMovieId:         From Southridge, use the source id. From the others, use the source MovieId.\n",
					"SouthridgeMovieId:           From Southridge, use the source id. From the others, use the source OnlineMovieId.\n",
					"ActorID:                     From Southridge, this is null. From the others, it's the source ActorId.\n",
					"ActorName:                   From Southridge, it's the exploded actor name. From the others, it is the ActorName.\n",
					"ActorGender:                 Southridge does not track this data. The on premises stores have Gender.\n",
					"Title:                       From Southridge, use title. From others, MovieTitle.\n",
					"Genre:                       From Southridge, use genre. From others, Category.\n",
					"Rating:                      Southridge has rating and the others have Rating.\n",
					"RuntimeMinutes:              Southridge has runtime, the others have RunTimeMin.\n",
					"TheatricalReleaseYear:       Southridge has releaseYear. The others don't have this data.\n",
					"PhysicalAvailabilityDate:    Southridge has availabilityDate. The others have ReleaseDate.\n",
					"StreamingAvailabilityDate:   Southridge has streamingAvailabilityDate. The others have no such data, as it does not apply to physical rentals.\n",
					"```\n",
					"\n",
					"### To join, cleanse, drop duplicates, etc. ... or not?\n",
					"\n",
					"At this stage, we want to focus on the **fatal** anomalies that would cause exceptions in downstream processing;\n",
					"e.g., inconsistent data types or formats.\n",
					"If we were loading this data directly into a final reporting schema, we would likely apply additional cleansing such as:\n",
					"\n",
					"- Look for and eliminate typos, e.g., PGg instead of PG\n",
					"- Normalize capitalization of titles, names, ratings, etc.\n",
					"- Look for and resolve conflicts in matched movies, e.g., Southridge thinks Mysterious Cube is a G-rated family movie while VanArsdel, Ltd. had it as a PG-13 rated Comedy\n",
					"- Look for variations in actor names and choose one to use consistently throughout the reporting schema, e.g., Vivica A. Fox vs Vivica Fox\n",
					"- Drop duplicates\n",
					"- etc., etc., etc.\n",
					"\n",
					"However, if we perform these operations now, then we may eliminate the opportunity to discover previously unrecognized value in the data.\n",
					"As a contrived example, consider a possibility that some actors and actresses would occassionally use their middle initial, but sometimes would not.\n",
					"Now, imagine that data scientists uncover a trend where films are more marketable when the cast does use their middle initial versus when they do not.\n",
					"Or maybe that only holds true in the Drama genre, but it does not hold in Family movies.\n",
					"If we have already chosen the person's \"usual\" billing and only kept that version in our conformed dataset,\n",
					"the the data scientists would never be able to see this."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# This is used in the following cells to create a new unique identifier\n",
					"\n",
					"uuidUdf = F.udf(lambda : str(uuid.uuid4()), StringType())"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"sr_conformed = sr_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"id\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"id\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"availabilityDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    col(\"streamingAvailabilityDate\").cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"genre\").alias(\"Genre\"), \\\n",
					"    col(\"title\").alias(\"Title\"), \\\n",
					"    col(\"rating\").alias(\"Rating\"), \\\n",
					"    col(\"runtime\").alias(\"RuntimeMinutes\"), \\\n",
					"    col(\"releaseYear\").alias(\"TheatricalReleaseYear\"), \\\n",
					"    sr_catalog[\"actor.name\"].alias(\"ActorName\")]) \\\n",
					"  .withColumn(\"ActorId\", F.lit(None).cast(StringType())) \\\n",
					"  .withColumn(\"ActorGender\", F.lit(None).cast(StringType())) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"# VanArsdel and Fourth Coffee are extremely similar\n",
					"\n",
					"va_conformed = va_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"MovieID\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"OnlineMovieID\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"ReleaseDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    F.lit(None).cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"Category\").alias(\"Genre\"), \\\n",
					"    col(\"MovieTitle\").alias(\"Title\"), \\\n",
					"    col(\"Rating\").alias(\"Rating\"), \\\n",
					"    col(\"RunTimeMin\").cast(LongType()).alias(\"RuntimeMinutes\"), \\\n",
					"    F.lit(None).cast(LongType()).alias(\"TheatricalReleaseYear\"), \\\n",
					"    col(\"ActorName\"), \\\n",
					"    col(\"MovieActorID\").alias(\"ActorID\"), \\\n",
					"    col(\"Gender\").alias(\"ActorGender\")]) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())\n",
					"\n",
					"fc_conformed = fc_catalog \\\n",
					"  .select([ \\\n",
					"    col(\"SourceSystemId\"), \\\n",
					"    col(\"MovieID\").alias(\"SourceSystemMovieId\"), \\\n",
					"    col(\"OnlineMovieID\").alias(\"SouthridgeMovieId\"), \\\n",
					"    col(\"ReleaseDate\").cast(TimestampType()).alias(\"PhysicalAvailabilityDate\"), \\\n",
					"    F.lit(None).cast(TimestampType()).alias(\"StreamingAvailabilityDate\"), \\\n",
					"    col(\"Category\").alias(\"Genre\"), \\\n",
					"    col(\"MovieTitle\").alias(\"Title\"), \\\n",
					"    col(\"Rating\").alias(\"Rating\"), \\\n",
					"    col(\"RunTimeMin\").cast(LongType()).alias(\"RuntimeMinutes\"), \\\n",
					"    F.lit(None).cast(LongType()).alias(\"TheatricalReleaseYear\"), \\\n",
					"    col(\"ActorName\"), \\\n",
					"    col(\"MovieActorID\").alias(\"ActorID\"), \\\n",
					"    col(\"Gender\").alias(\"ActorGender\")]) \\\n",
					"  .withColumn(\"CatalogId\", uuidUdf())"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"# The full catalog is now a straightforward union\n",
					"\n",
					"full_catalog = sr_conformed.union(va_conformed).union(fc_conformed)\n",
					"full_catalog.write.mode(\"overwrite\").parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/conformed/catalog\")"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"# Let's rehydrate and confirm that everything checks out\n",
					"\n",
					"rehydrated_catalog = spark.read.parquet(\"abfss://lgnsynapsefs@lgnsynapselake.dfs.core.windows.net/mdwoh/conformed/catalog\")\n",
					"\n",
					"sr_rehydrated = rehydrated_catalog.filter(\"SourceSystemID=='SR'\")\n",
					"\n",
					"sr_actors_per_movie = sr_rehydrated \\\n",
					"  .groupby(col('SourceSystemMovieId')) \\\n",
					"  .agg(F.count(F.lit(1)).alias('ActorCount'))\n",
					"\n",
					"print('The number of rows from Southridge is ', sr_rehydrated.count())\n",
					"print('The number of distinct movies from Southridge is', sr_actors_per_movie.count())\n",
					"print(sr_actors_per_movie.limit(1).collect())"
				],
				"execution_count": 13
			}
		]
	}
}